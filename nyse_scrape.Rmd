---
title: "C2 - Term Project - stocklist"
author: "Son Nam Nguyen"
date: "`r format(Sys.time(), '%d %B %Y')`"
output:
  prettydoc::html_pretty:
  toc: true
  theme: architect
  highlight: github
---

## Setup

```{r pacman, echo=F, message=F}

setwd("~/Desktop/repos/c2-nyse-term-project")

# Loading packages with pacman
if (!require("pacman")) {
  install.packages("pacman")
}

pacman::p_load(tidyverse, rvest, data.table,
               xml2, stringr, logger, heatmaply)

rooturl <- 'http://eoddata.com/stocklist/NYSE/'

```

## Get One Page

```{r get data}

get_one_page <- function(url){
  
  t <- read_html(url)
  
  logger::log_info('URL parsed')
  
  #init empty list
  mydata <- list()
  
  tryCatch(
    {
      for (i in 1:9){
      mydata[[i]] <- t %>% 
        html_nodes(paste0('#ctl00_cph1_divSymbols td:nth-child(',i,')')) %>% html_text() %>% list()
      }
      logger::log_info("Got all the columns!")
    },
    error = function(e){
        stop("Couldn't get all the columns.")
    }
  )
  #loop through columns of the table and append
  
  df <- data.frame(mydata)
  
  logger::log_info('Dataframe formed')
  
  return(df)
}

```

# Get Ticker Table

```{r urls, message=F, warning=F}

get_all_stock <- function(rooturl){
  
  start.time <- Sys.time()
  
  #init empty list of urls
  urls <- list()
  
  #generate urls for pages
  for (i in 1:length(letters)){
    urls[[i]] <- paste0(rooturl,letters[i],".htm")
  }
  
  logger::log_info('URLs generated for page {letters[i]}!')
  
  #get all and bind it together
  stocklist <- rbindlist(lapply(urls, get_one_page))
  
  logger::log_info('Got all the data!')
  
  end.time <- Sys.time()
  time.taken <- end.time - start.time
  print(time.taken)
  
  return(stocklist)
}

stocklist_raw <- get_all_stock(rooturl)

#rename columns
colnames(stocklist_raw) <- c('code', 'name', 'high', 'low', 'close', 'volume', 'change', 'direction', 'price')

```

# Get Fundamentals tables

```{r, message=F, warning=F}

rooturl2 <- 'https://eoddata.com/stockquote/NYSE/'

colnames <- c("sector", "industry", "pe_ratio", "peg_ratio", "eps", "divyield", "ptb", "pts", "ebitda", "shares", "market_cap", "52wk_range")

tickers <- stocklist_raw[["code"]]

#download all subpages for tickers incrementally

for (i in 1:length(tickers)){
  if (!file.exists(paste0("htmls/",tickers[i],".htm"))){
      url <- paste0(rooturl2,tickers[i],".htm")
      download.file(url, destfile = paste0('htmls/',tickers[i],'.htm'), quiet = T)
      logger::log_info("Stock {tickers[i]} HTML downloaded")
  }else{
    logger::log_info("Page are already downloaded, skipping.")
  }
}

#zip-unzip

get_all_fundamentals <- function(tickers){
  
  start.time <- Sys.time()
  
  #init empty dataframe
  fundamentals <- NULL
  
  #get fundamentals for list of tickers
  for (i in 1:length(tickers)){
    subpage <- paste0("htmls/",tickers[i],".htm")
    f <- read_html(subpage)
    values <- f %>% html_nodes('#ctl00_cph1_divFundamentals td:nth-child(2)') %>% html_text()
    fundamentals <- rbind(fundamentals, data.frame(matrix(unlist(values), ncol=length(values), byrow=F)))
    logger::log_info("Got table for ticker {tickers[i]}!")
  }
  
  colnames(fundamentals) <- colnames
  
  end.time <- Sys.time()
  time.taken <- end.time - start.time
  print(time.taken)
  
  return(fundamentals)
  
}

fundamentals <- get_all_fundamentals(tickers)

```

# Merge tables

```{r merge}

nyse_raw <- cbind(stocklist_raw, fundamentals)

#write to csv
write.csv(nyse_raw, 'nyse_raw.csv', row.names=FALSE)

#read csv
nyse_raw <- read.csv("nyse_raw.csv", sep = ',')

```

# Data Cleaning

```{r transform, warnings=F}

#fix number formatting
formatter <- function(col){
  num <- gsub('B', 'e3', col)
  num <- gsub('M', '', num)
  num <- gsub('K', 'e-3', num)
  format(as.numeric(num), scientific = FALSE, big.mark = ",")
}

#transform to million
cols <- c("ebitda", "shares", "market_cap")
nyse_raw[cols] <- lapply(nyse_raw[cols], formatter)

#cleanup thousand separators, and cast
nyse_clean <- nyse_raw %>%
          select(-c("direction")) %>%
          mutate_all(funs(gsub(",", "", .)), select(., high:price)) %>%
          separate(X52wk_range, c('52wk_range_low', '52wk_range_high'), sep = " - ") %>% 
          mutate(high = as.numeric(high),
                 low = as.numeric(low),
                 close = as.numeric(close),
                 change = round(as.numeric(change), 2),
                 volume = as.integer(volume)/10^6,
                 price = as.numeric(price),
                 pe_ratio = round(as.numeric(pe_ratio), 2),
                 peg_ratio = round(as.numeric(peg_ratio), 2),
                 eps = round(as.numeric(eps), 2),
                 divyield = round(as.numeric(divyield)/100, 2),
                 ptb = round(as.numeric(ptb), 2),
                 pts = round(as.numeric(pts), 2),
                 ebitda = round(as.numeric(ebitda), 2),
                 shares = round(as.numeric(shares), 2),
                 market_cap = round(as.numeric(market_cap), 2),
                 `52wk_range_low` = as.numeric(`52wk_range_low`),
                 `52wk_range_high` = as.numeric(`52wk_range_high`))
         
nyse_clean[nyse_clean == ""] <- NA

```

# Visualizations

```{r dataviz}

#corrplot
#corr <- nyse_clean %>% select(c("volume", "price", "eps", "divyield", "ebitda", "shares", "market_cap")) %>% na.omit() %>% cor() %>% round(1)

#sectors with the largest market cap
nyse_clean %>% 
  na.omit() %>% 
  arrange(desc(market_cap)) %>%
  slice(1:5) %>%
  ggplot() +
    geom_col(aes(reorder(sector, market_cap), market_cap, fill = sector)) +
  theme_bw() +
  coord_flip() +
  labs(title = "Sectors with the largest market cap (M)",
       y = "Market Cap",
       x = "",
       caption = "Source: eoddata.com") +
  scale_fill_viridis_d(name = "Sector")

#stocks with the most volume
nyse_clean %>% 
  arrange(desc(volume)) %>%
  slice(1:5) %>%
  ggplot() +
    geom_col(aes(reorder(code, volume), volume), fill = "firebrick2", color = "firebrick4") +
  theme_bw() +
  coord_flip() +
  labs(title = "Stocks with the most volume (M)",
       y = "Volume",
       x = "",
       caption = "Source: eoddata.com")

#stocks with the largest dividents
nyse_clean %>% 
  arrange(desc(divyield)) %>%
  slice(1:5) %>%
  ggplot() +
    geom_col(aes(reorder(code, divyield), divyield), fill = "firebrick2", color = "firebrick4") +
  theme_bw() +
  coord_flip() +
  labs(title = "Stocks with the largest divident yields",
       y = "Yield",
       x = "",
       caption = "Source: eoddata.com") +
  scale_y_continuous(labels=scales::percent)

```